<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: MySQL | My Octopress Blog]]></title>
  <link href="http://blog.randywallace.com/blog/categories/mysql/atom.xml" rel="self"/>
  <link href="http://blog.randywallace.com/"/>
  <updated>2013-08-29T11:42:57-04:00</updated>
  <id>http://blog.randywallace.com/</id>
  <author>
    <name><![CDATA[Randy D. Wallace Jr.]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Show Hosts Connected to MySQL]]></title>
    <link href="http://blog.randywallace.com/blog/2013/08/29/show-hosts-connected-to-mysql/"/>
    <updated>2013-08-29T10:21:00-04:00</updated>
    <id>http://blog.randywallace.com/blog/2013/08/29/show-hosts-connected-to-mysql</id>
    <content type="html"><![CDATA[<p>For the terminal jockies, this is a quick and dirty for finding who, or what, is connected to your server.
This proves useful when you&rsquo;re running in tmux and want a pane for tracking what is left to disconnect
from your database before shutting it down.</p>

<p>This could be done in tools like mytop, but who needs all that overhead when you have this:</p>

<p>```</p>

<h1>!/bin/bash</h1>

<p>MYSQL=/usr/bin/mysql                                   <br/>
DB_HOST=&lsquo;127.0.0.1&rsquo;
DB_USER=&lsquo;user&rsquo;
DB_PASS=&lsquo;pass&rsquo;
DB=&lsquo;information_schema&rsquo;</p>

<p>read -r -d &lsquo;&rsquo; HOST_QUERY &lt;&lt;&lsquo;EOF&rsquo;                                     <br/>
SELECT DISTINCT SUBSTRING_INDEX(<code>host</code>, &ldquo;:&rdquo;, 1) AS HOST              <br/>
FROM PROCESSLIST                                                     <br/>
EOF</p>

<p>$MYSQL -u $DB_USER -p"$DB_PASS" -h $DB_HOST -N -B $DB -e &ldquo;$HOST_QUERY&rdquo;
```</p>

<p>Mix that up with a little watch magic, and you&rsquo;ve got realtime updates:</p>

<p><code>
watch -n 1 ./connected_hosts.sh
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pulling a Large MySQL Table into elasticsearch]]></title>
    <link href="http://blog.randywallace.com/blog/2013/08/27/pulling-a-large-mysql-table-into-elasticsearch/"/>
    <updated>2013-08-27T23:47:00-04:00</updated>
    <id>http://blog.randywallace.com/blog/2013/08/27/pulling-a-large-mysql-table-into-elasticsearch</id>
    <content type="html"><![CDATA[<p>If you need to perform realtime queries against a huge MySQL table, but are no longer able to due to
the size of the table, read on to find out how to make elasticsearch do the heavy lifting for you!</p>

<p>This solution includes the ability to perform regular updates to elasticsearch of new data that gets pushed
to the table in MySQL.</p>

<!-- more -->


<h2>Requirements</h2>

<ul>
<li>A MySQL table with an AUTO_INCREMENT primary key which receives only INSERTs</li>
<li>A running elasticsearch cluster</li>
<li>The <a href="https://github.com/jprante/elasticsearch-river-jdbc">Elasticsearch JDBC River</a> plugin installed</li>
</ul>


<h2>Why not use the <a href="https://github.com/jprante/elasticsearch-river-jdbc/wiki/Strategies">simple</a> or <a href="https://github.com/jprante/elasticsearch-river-jdbc/wiki/Strategies">table</a> strategy?</h2>

<p>For the <a href="https://github.com/jprante/elasticsearch-river-jdbc/wiki/Strategies">simple</a> strategy, you need an
immutable SQL Statement to poll data.  Choosing a query that can survive downtime but preserve recent data
is all but impossible to guarantee.</p>

<p>Does this make sense using a one hour polling period, assuming that we want to keep the index current to within
the last hour?</p>

<p><code>
SELECT id AS _id, domain, ts FROM mysql_table WHERE ts &gt;= DATE_SUB(NOW(), INTERVAL 1 HOUR);
</code></p>

<p>As long as we are telling elasticsearch that the primary key is the _id field, elasticsearch will only
update existing entries from the last run, so no issues there.</p>

<p>This, though, is a huge waste of resources and provides no reliability.  If a poll fails for whatever reason,
data is more than likely lost if the time since last poll is greater than one hour (or more if the INTERVAL is
increased).  There is no way to recover the lost data without repopulating the river from a known point by
replacing the river with a oneshot strategy query and then restoring the original river.</p>

<p>For the <a href="https://github.com/jprante/elasticsearch-river-jdbc/wiki/Strategies">table</a> strategy, you have to alter
the table to add new columns for tracking.   For most production environments, this is a non-option.</p>

<h2>Get on with it!</h2>

<p>So, considering the above issues, I decided to use the oneshot strategy.</p>

<h3>The Tracking Table</h3>

<p>I used a table in MySQL to track each run of new data into elasticsearch.  As you&rsquo;ll see later, I use
this table to determine the start and stop key of each oneshot run of data.  This is the schema I used:</p>

<p><code>``
CREATE TABLE</code>elastic_river_meta<code>
  (</code>id` NOT NULL AUTO_INCREMENT,</p>

<pre><code>`next_index_id` bigint(20) NOT NULL,
`timestamp` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
PRIMARY KEY (`id`) );
</code></pre>

<p>```</p>

<h3>Creating the Mapping for the elasticsearch Index</h3>

<p>Before we get into starting the river, first lets generate a sensible mapping for table.  You can skip this
and the plugin will sensibly determine the defaults for you.  I found, though, that there were subtle
changes I needed to make to run terms facet queries against string fields which required reindexing.</p>

<p>Assuming that the <code>domain</code> column in the SELECT example above is a domain name, I want to both index the
field for keywords using the standard token analyzer (which will tokenize on the &lsquo;.&rsquo;s in the domain name) and
I want the entire domain name to be indexed as a single keyword.  Doing so requires a
<a href="http://www.elasticsearch.org/guide/reference/mapping/multi-field-type/">Multi Field</a> type in the mapping.</p>

<p>```
curl -XPOST http://localhost:9200/mysql_table -d &lsquo;
{
  &ldquo;mappings&rdquo; : {</p>

<pre><code>"mysql_row": {
  "properties" : {
    "domain" : {
      "type" : "multi_field",
      "fields" : {
        "domain" : {
          "type" : "string",
          "index" : "analyzed"
        },
        "exact" : {
          "type" : "string",
          "index" : "not_analyzed"
        }
      }
    },
    "sent_date" : {
      "type" : "date",
      "format" : "dateOptionalTime"
    }
  }
}
</code></pre>

<p>  }
}&lsquo;
```</p>

<h3>Preloading the meta table to specify the start point and end point for the first run</h3>

<p>Let&rsquo;s go ahead and put an entry in the <code>elastic_river_meta</code> table to specify the starting and ending
point for the initial run.  This would run for a while, depending on how much data you have.</p>

<p><code>
INSERT INTO `elastic_river_meta` SET `next_index_id` = 0;
INSERT INTO `elastic_river_meta` SELECT MAX(id) from `mysql_table`;
</code></p>

<h3>Loading the existing data into elasticsearch</h3>

<p>Now we can yank everything within the <code>id</code>&rsquo;s populated in the <code>elastic_river_meta</code> table with
our first run of the oneshot strategy.</p>

<p>If you&rsquo;re not sure everything is going to work, or you want to do some testing, just lower the
value of the second row you populated in the <code>elastic_river_meta</code> table.</p>

<p>This is the query we&rsquo;ll be running against MySQL:</p>

<p>```
select id as _id,</p>

<pre><code>   domain, 
   ts 
</code></pre>

<p>from mysql_table
where
  id > (select next_index_id</p>

<pre><code>    from elastic_river_meta
    order by id desc limit 1,1) 
</code></pre>

<p>  and
  id &lt;= (select next_index_id</p>

<pre><code>     from elastic_river_meta 
     order by id desc limit 1);
</code></pre>

<p>```</p>

<p>And this is the command that will run it.</p>

<p>```
/usr/bin/curl -XPUT &lsquo;localhost:9200/<em>river/mysql_table/</em>meta&rsquo; -d &lsquo;{</p>

<pre><code>"type" : "jdbc",
"jdbc" : {
    "driver" : "com.mysql.jdbc.Driver",
    "url" : "jdbc:mysql://&lt;host&gt;:3306/&lt;DB&gt;",
    "user" : "&lt;user&gt;",
    "password" : "&lt;password&gt;",
    "strategy": "oneshot",
    "sql" : "select id as _id, domain, ts from mysql_table where id &gt; (select next_index_id from elastic_river_meta order by id desc limit 1,1) and id &lt;= (select next_index_id from elastic_river_meta order by id desc limit 1);"
},
"index" : {
    "index" : "mysql_table",
    "type" : "mysql_row",
    "bulk_size": 500
}
</code></pre>

<p>}&lsquo;
```</p>

<p>Watch the log to keep an eye on when this finishes.</p>

<h3>Ok, my data is loaded and <a href="http://three.kibana.org">looks</a> OK!</h3>

<p>Now that the prepwork is finished, here is a script that will:</p>

<ul>
<li>insert a new <code>MAX(id)</code> into the <code>elastic_river_meta</code> table</li>
<li>remove the existing river</li>
<li>add a new river with updated params for the ID range</li>
</ul>


<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span> (update_index_to_latest.sh)</span> <a href='/downloads/code/update_index_to_latest.sh'>download</a></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'>
</span><span class='line'><span class="nv">HOST</span><span class="o">=</span><span class="s1">&#39;127.0.0.1&#39;</span>
</span><span class='line'><span class="nv">USER</span><span class="o">=</span><span class="s1">&#39;user&#39;</span>
</span><span class='line'><span class="nv">PASS</span><span class="o">=</span><span class="s1">&#39;pass&#39;</span>
</span><span class='line'><span class="nv">DB</span><span class="o">=</span><span class="s1">&#39;db&#39;</span>
</span><span class='line'><span class="nv">MYSQL_CMD</span><span class="o">=</span><span class="s2">&quot;mysql -u $USER -p$PASS -h$HOST $DB&quot;</span>
</span><span class='line'><span class="nv">ELST_HOST</span><span class="o">=</span><span class="s1">&#39;127.0.0.1&#39;</span>
</span><span class='line'><span class="nv">CURL</span><span class="o">=</span>/usr/bin/curl
</span><span class='line'><span class="nv">INDEX</span><span class="o">=</span><span class="s1">&#39;mysql_table&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>update_elastic_to_latest <span class="o">{</span>
</span><span class='line'>  <span class="nv">$MYSQL_CMD</span> <span class="s">&lt;&lt;END</span>
</span><span class='line'><span class="s">INSERT INTO elastic_river_meta (next_index_id)</span>
</span><span class='line'><span class="s">SELECT MAX(index_id) from mysql_table;</span>
</span><span class='line'><span class="s">END</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>get_latest_index_id <span class="o">{</span>
</span><span class='line'>  <span class="nv">LATEST_ID</span><span class="o">=</span><span class="k">$(</span><span class="nv">$MYSQL_CMD</span> -N -B <span class="s">&lt;&lt;END</span>
</span><span class='line'><span class="s">SELECT next_index_id from elastic_river_meta order by id desc limit 1;</span>
</span><span class='line'><span class="s">END</span>
</span><span class='line'><span class="k">)</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>get_second_latest_index_id <span class="o">{</span>
</span><span class='line'>  <span class="nv">SECOND_LATEST_ID</span><span class="o">=</span><span class="k">$(</span><span class="nv">$MYSQL_CMD</span> -N -B <span class="s">&lt;&lt;END</span>
</span><span class='line'><span class="s">SELECT next_index_id from elastic_river_meta order by id desc limit 1,1;</span>
</span><span class='line'><span class="s">END</span>
</span><span class='line'><span class="k">)</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>delete_jdbc_river <span class="o">{</span>
</span><span class='line'>  <span class="nv">$CURL</span> -XDELETE <span class="k">${</span><span class="nv">ELST_HOST</span><span class="k">}</span>:9200/_river/<span class="k">${</span><span class="nv">INDEX</span><span class="k">}</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">function </span>install_jdbc_river <span class="o">{</span>
</span><span class='line'>  get_latest_index_id
</span><span class='line'>  get_second_latest_index_id
</span><span class='line'>  <span class="nb">read</span> -r -d <span class="s1">&#39;&#39;</span> _QRY <span class="s">&lt;&lt;EOF</span>
</span><span class='line'><span class="s">SELECT </span>
</span><span class='line'><span class="s">  id as _id, </span>
</span><span class='line'><span class="s">  domain, ts</span>
</span><span class='line'><span class="s">FROM mysql_table</span>
</span><span class='line'><span class="s">WHERE</span>
</span><span class='line'><span class="s">  id &gt; ${SECOND_LATEST_ID}</span>
</span><span class='line'><span class="s">  AND</span>
</span><span class='line'><span class="s">  id &lt;= ${LATEST_ID}</span>
</span><span class='line'><span class="s">EOF</span>
</span><span class='line'>  <span class="nb">read</span> -r -d <span class="s1">&#39;&#39;</span> _DTA <span class="s">&lt;&lt;EOF</span>
</span><span class='line'><span class="s">{</span>
</span><span class='line'><span class="s">  &quot;type&quot; : &quot;jdbc&quot;,</span>
</span><span class='line'><span class="s">  &quot;jdbc&quot; : {</span>
</span><span class='line'><span class="s">      &quot;driver&quot; : &quot;com.mysql.jdbc.Driver&quot;,</span>
</span><span class='line'><span class="s">      &quot;url&quot; : &quot;jdbc:mysql://${HOST}:3306/${DB}&quot;,</span>
</span><span class='line'><span class="s">      &quot;user&quot; : &quot;${USER}&quot;,</span>
</span><span class='line'><span class="s">      &quot;password&quot; : &quot;${PASS}&quot;,</span>
</span><span class='line'><span class="s">      &quot;strategy&quot;: &quot;oneshot&quot;,</span>
</span><span class='line'><span class="s">      &quot;sql&quot; : &quot;$(echo ${_QRY})&quot;</span>
</span><span class='line'><span class="s">  },</span>
</span><span class='line'><span class="s">  &quot;index&quot; : {</span>
</span><span class='line'><span class="s">      &quot;index&quot; : &quot;${INDEX}&quot;,</span>
</span><span class='line'><span class="s">      &quot;type&quot; : &quot;mysql_row&quot;,</span>
</span><span class='line'><span class="s">      &quot;bulk_size&quot;: 500</span>
</span><span class='line'><span class="s">  }</span>
</span><span class='line'><span class="s">}</span>
</span><span class='line'><span class="s">EOF</span>
</span><span class='line'>
</span><span class='line'>  <span class="nv">$CURL</span> -XPUT <span class="k">${</span><span class="nv">ELST_HOST</span><span class="k">}</span>:9200/_river/<span class="k">${</span><span class="nv">INDEX</span><span class="k">}</span>/_meta -d <span class="s2">&quot;${_DTA}&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'>delete_jdbc_river
</span><span class='line'>update_elastic_to_latest
</span><span class='line'>install_jdbc_river
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>You can run that script as an executable as much as you want, and
it will always pull the latest data.</p>

<h3>Put it in a cronjob</h3>

<p>All that is left to do now is run this script in a cronjob.  Here
is an example that runs it every hour:</p>

<p><code>
00 *    * * *   root    /home/user/update_index_to_latest.sh &gt; /dev/null 2&gt;&amp;1
</code></p>

<h2>Still missing</h2>

<p>I don&rsquo;t want to perform an update if the current jdbc river is still pulling data,
but there is no way of getting this information from elasticsearch.  As such, the
best way I see to do this is by Running a query against elasticsearch to see if the
<code>LATEST\_ID</code>  exists in elasticsearch before performing an update.</p>

<p>My script also doesn&rsquo;t check if there is actually any new data.  The consequences
of this are minimal, insofar that what the query ends up returning is one row of
the most recent id.  Regardless, I would like to add this check.</p>
]]></content>
  </entry>
  
</feed>
